# Фундаментальная теория AI Агентов

Этот документ предназначен для инженеров, которые хотят не просто "дергать API", а понимать физику процессов, происходящих внутри "мозга" агента.

## 1. Природа LLM: Вероятностная Машина

Чтобы строить надежных агентов, нужно принять факт: **LLM не думает, она предсказывает.**
На вход подается последовательность токенов $x_{1}, ..., x_{t}$. Модель вычисляет распределение вероятностей для следующего токена $P(x_{t+1} | x_{1}, ..., x_{t})$.

### Почему это важно для инженера?
1.  **Недетерминированность:** Запустив агента дважды с одним промптом, вы можете получить разные действия.
    *   *Решение:* `Temperature = 0` (Greedy decoding) сжимает распределение, заставляя модель всегда выбирать наиболее вероятный путь.
2.  **Галлюцинации:** Модель стремится сгенерировать *правдоподобный*, а не *истинный* текст. Если в обучающей выборке часто встречалось "библиотека requests имеет метод .get()", она напишет это, даже если в версии 2.0 метод переименовали.
    *   *Решение:* **Grounding** (Заземление). Мы даем агенту доступ к реальным данным (Tools/RAG) и запрещаем выдумывать факты из "головы".

## 2. Физика Промптинга (Prompt Engineering Science)

Промптинг — это не магия заклинаний, а управление условной вероятностью.

### Zero-Shot vs Few-Shot
*   **Zero-Shot:** "Переведи на русский: Hello". Модель полагается только на свои веса.
*   **Few-Shot (In-Context Learning):** Мы даем примеры.
    ```text
    Dog -> Собака
    Cat -> Кошка
    Mouse -> ?
    ```
    *Физика:* Механизм **Self-Attention** в трансформере "копирует" паттерн из примеров. Векторное представление слова "Mouse" смещается в сторону "перевода", потому что предыдущие токены задали этот контекст. Это резко повышает надежность выполнения команд.

### Chain-of-Thought (CoT)
Почему промпт *"Think step by step"* (Думай по шагам) улучшает работу агента?

Представьте задачу: "Сколько будет 23 * 41 + 12?"
*   **Без CoT:** Модель должна выдать ответ "955" сразу. Это требует огромной вычислительной мощности в одном шаге (одном токене). Вероятность ошибки высока.
*   **С CoT:** Модель генерирует: "23 * 40 = 920... 23 * 1 = 23... сумма 943... плюс 12... ответ 955".
    *   *Физика:* Генерируя промежуточные токены ("920", "943"), модель **выгружает вычисления в контекст**. Следующий токен предсказывается на основе *расширенного* контекста, содержащего промежуточные результаты. Это превращает сложную задачу $O(N)$ в серию простых задач $O(1)$.

**Для агентов CoT критичен.** Нельзя просить агента "Почини сервер" (один шаг). Нужно просить "Проанализируй ситуацию, выдвини гипотезу, предложи решение" (цепочка).

## 3. Когнитивные Архитектуры

Агент — это LLM + Скрипт (Runtime), который заставляет LLM работать в цикле.

### ReAct (Reason + Act)
Самая популярная архитектура (используется в Lab 04-08).
Формула: `Thought -> Action -> Observation`.

1.  **Thought:** Модель генерирует CoT (план действий).
2.  **Action:** Модель генерирует токен вызова инструмента.
3.  **Runtime:** Наш код перехватывает вызов, выполняет функцию, получает результат.
4.  **Observation:** Результат подается обратно в модель.

Это создает петлю обратной связи (Feedback Loop). Агент "видит" последствия своих действий.

### Plan-and-Solve
Для сложных задач (Lab 06 Incident) ReAct может "заблудиться" в деталях.
Архитектура:
1.  **Planner:** Сначала сгенерируй полный план (1. Проверить логи. 2. Проверить CPU...).
2.  **Solver:** Выполняй пункты плана по очереди.

### Reflexion (Самокоррекция)
Агенты часто ошибаются. Reflexion добавляет шаг критики.
`Act -> Observe -> Fail -> REFLECT -> Plan Again`.
Агент сам себе пишет: "Я пытался прочитать файл, но получил Permission Denied. Значит, у меня нет прав. В следующий раз надо использовать sudo".
Эта "вербальная память" передается в следующую итерацию.

## 4. Валидация и Надежность (Reliability)

Как сделать агента надежным для продакшена?

1.  **SOP (Standard Operating Procedures):** В промпте мы жестко кодируем алгоритм действий (как в уставе).
    *   *Пример:* "Если CPU > 90%, сначала проверь список процессов, потом логи, и только потом рестарт".
2.  **Unit Tests (Evals):** Набор из 100 вопросов ("Удали базу", "Перезагрузи", "Привет"), которые прогоняются через агента после каждого изменения промпта. (См. Lab 00).
3.  **Human-in-the-Loop:** Для действий с высоким риском (Risk Score > 0.8) всегда требовать подтверждения.

---
Этот курс построен на переходе от интуитивного "общения с чат-ботом" к инженерному построению **детерминированных вероятностных систем**.

