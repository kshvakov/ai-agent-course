# 01. Физика LLM — как работает "мозг" агента

Чтобы управлять агентом, нужно понимать, как работает его "мозг".

## Вероятностная природа

**Ключевой факт:** LLM не думает, она предсказывает.

LLM — это функция `NextToken(Context) -> Distribution`.  
На вход подается последовательность токенов $x_1, ..., x_t$. Модель вычисляет распределение вероятностей для следующего токена:

$$P(x_{t+1} | x_1, ..., x_t)$$

### Что это значит на практике?

#### Пример 1: DevOps
Промпт: `"Проверь статус сервера"`
- Модель видит контекст и предсказывает: "Я вызову инструмент `check_status`" (вероятность 0.85)
- Или: "Я отвечу текстом" (вероятность 0.15)

#### Пример 2: Support
Промпт: `"Пользователь жалуется на ошибку 500"`
- Модель предсказывает: "Сначала соберу контекст через `get_ticket_details`" (вероятность 0.9)
- Или: "Сразу отвечу шаблоном" (вероятность 0.1)

#### Пример 3: Data Analytics
Промпт: `"Покажи продажи за последний месяц"`
- Модель предсказывает: "Сформулирую SQL-запрос через `sql_select`" (вероятность 0.95)
- Или: "Отвечу текстом без данных" (вероятность 0.05)

### Почему это важно для инженера?

#### 1. Недетерминированность

Запустив агента дважды с одним промптом, вы можете получить разные действия.

**Пример:**
```
Запрос 1: "Проверь сервер"
Ответ 1: [Вызывает check_status]

Запрос 2: "Проверь сервер" (тот же промпт)
Ответ 2: [Отвечает текстом "Сервер работает"]
```

**Решение:** `Temperature = 0` (Greedy decoding) сжимает распределение, заставляя модель всегда выбирать наиболее вероятный путь.

```go
req := openai.ChatCompletionRequest{
    Temperature: 0,  // Детерминированное поведение
    // ...
}
```

#### 2. Галлюцинации

Модель стремится сгенерировать *правдоподобный*, а не *истинный* текст.

**DevOps пример:** Модель может написать "используй флаг `--force`" для команды, которая его не поддерживает.

**Data пример:** Модель может сгенерировать SQL с несуществующим полем `user.email` вместо `users.email`.

**Support пример:** Модель может "выдумать" решение проблемы, которого нет в базе знаний.

**Решение:** **Grounding** (Заземление). Мы даем агенту доступ к реальным данным (Tools/RAG) и запрещаем выдумывать факты.

```go
systemPrompt := `You are a DevOps assistant.
CRITICAL: Never invent facts. Always use tools to get real data.
If you don't know something, say "I don't know" or use a tool.`
```

## Токены и контекстное окно

### Что такое токен?

**Токен** — это единица текста, которую обрабатывает модель.
- Один токен ≈ 0.75 слова (в английском)
- В русском: одно слово ≈ 1.5 токена

**Пример:**
```
Текст: "Проверь статус сервера"
Токены: ["Проверь", " статус", " сервера"]  // ~3 токена
```

### Контекстное окно (Context Window)

**Контекстное окно** — это "оперативная память" модели.
- GPT-3.5: 4k токенов (~3000 слов)
- GPT-4 Turbo: 128k токенов (~96000 слов)
- Llama 3 70B: 8k токенов

**Что это значит для агента?**

Все, что агент "знает" о текущей задаче — это то, что влезает в контекстное окно (Prompt + History).

**Пример расчета:**
```
Контекстное окно: 4k токенов
System Prompt: 200 токенов
История диалога: 3000 токенов
Результаты инструментов: 500 токенов
Осталось места: 300 токенов
```

Если история переполняется, агент "забывает" начало разговора.

**Модель Stateless:** Она не помнит ваш прошлый запрос, если вы не передали его снова в `messages`.

```go
// Каждый запрос должен включать всю историю
messages := []openai.ChatCompletionMessage{
    {Role: "system", Content: systemPrompt},
    {Role: "user", Content: "Проверь сервер"},
    {Role: "assistant", Content: "Проверяю..."},
    {Role: "tool", Content: "Server is ONLINE"},
    {Role: "user", Content: "А что с базой?"},  // Агент видит всю историю!
}
```

## Температура (Temperature)

**Температура** — это параметр энтропии распределения вероятностей.

```go
Temperature = 0  // Детерминировано (для агентов!)
Temperature = 0.7  // Баланс креативности и стабильности
Temperature = 1.0+  // Креативно, но нестабильно
```

### Когда использовать какое значение?

| Temperature | Использование | Пример |
|-------------|---------------|--------|
| 0.0 | Агенты, JSON-генерация, Tool Calling | DevOps-агент должен стабильно вызывать `restart_service`, а не "творить" |
| 0.1-0.3 | Структурированные ответы | Support-агент генерирует шаблоны ответов |
| 0.7-1.0 | Креативные задачи | Product-агент пишет маркетинговые тексты |

**Практический пример:**

```go
// ПЛОХО: Для агента
req := openai.ChatCompletionRequest{
    Temperature: 0.9,  // Слишком случайно!
    // ...
}

// ХОРОШО: Для агента
req := openai.ChatCompletionRequest{
    Temperature: 0,  // Максимальная детерминированность
    // ...
}
```

## Выбор модели для локального запуска

Не все модели одинаково хороши для агентов.

### Критерии выбора

1. **Поддержка Function Calling:** Модель должна уметь генерировать структурированные вызовы инструментов.
   - ✅ Хорошо: `Hermes-2-Pro`, `Llama-3-Instruct`, `Mistral-7B-Instruct`
   - ❌ Плохо: Базовые модели без fine-tuning на tools

2. **Размер контекста:** Для сложных задач нужен большой контекст.
   - Минимум: 4k токенов
   - Рекомендуется: 8k+

3. **Качество следования инструкциям:** Модель должна строго следовать System Prompt.
   - Проверяется через Lab 00 (Capability Check)

### Как проверить модель?

См. `Lab 00: Model Capability Benchmark`

## Типовые проблемы и их решение

### Проблема 1: Модель недетерминированна

**Симптом:** Один и тот же промпт дает разные результаты.

**Решение:**
```go
Temperature: 0,  // Всегда используйте для агентов
```

### Проблема 2: Контекст переполняется

**Симптом:** Агент "забывает" начало разговора.

**Решение:**
```go
// Обрезка истории (оставляем только последние N сообщений)
if len(messages) > maxHistoryLength {
    messages = append(
        []openai.ChatCompletionMessage{messages[0]},  // System
        messages[len(messages)-maxHistoryLength+1:]...,  // Последние
    )
}
```

### Проблема 3: Галлюцинации

**Симптом:** Модель выдумывает факты.

**Решение:**
- Используйте Tools для получения реальных данных
- Запретите модели выдумывать в System Prompt
- Используйте RAG для доступа к документации

## Чек-лист: Настройка модели для агента

- [ ] Модель поддерживает Function Calling (проверено через Lab 00)
- [ ] `Temperature = 0` установлена
- [ ] Контекстное окно достаточно большое (минимум 4k токенов)
- [ ] System Prompt запрещает галлюцинации
- [ ] История диалога управляется (обрезается при переполнении)

## Мини-упражнения

### Упражнение 1: Подсчет токенов

Напишите функцию, которая приблизительно подсчитывает количество токенов в тексте:

```go
func estimateTokens(text string) int {
    // Примерная оценка: 1 токен ≈ 4 символа
    return len(text) / 4
}
```

### Упражнение 2: Обрезка истории

Реализуйте функцию обрезки истории сообщений:

```go
func trimHistory(messages []ChatCompletionMessage, maxTokens int) []ChatCompletionMessage {
    // Оставляем System Prompt + последние сообщения, которые влезают в maxTokens
    // ...
}
```

## Что дальше?

После изучения физики LLM переходите к:
- **[02. Промптинг как Программирование](../02-prompt-engineering/README.md)** — как управлять поведением модели через промпты

---

**Навигация:** [← Предисловие](../00-preface/README.md) | [Оглавление](../README.md) | [Промптинг →](../02-prompt-engineering/README.md)

