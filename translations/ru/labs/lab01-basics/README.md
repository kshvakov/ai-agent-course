# Lab 01: Hello, LLM! (Basics & Memory)

## Цель
Научиться работать с OpenAI API (или совместимым локальным API) на Go, реализовать базовый цикл чата и механизм памяти (History).

## Теория
Любое общение с LLM (ChatGPT, Llama 3) — это stateless процесс. Модель не помнит, что вы писали секунду назад. Чтобы создать иллюзию диалога, мы каждый раз отправляем **весь** список предыдущих сообщений (историю).

Структура сообщения обычно такая:
*   `System`: Инструкция для роли ("Ты DevOps инженер...").
*   `User`: Вопрос пользователя ("Как дела?").
*   `Assistant`: Ответ модели.

## Задание
В файле `main.go` вы найдете заготовку консольного чата.

1.  **Инициализация:** Создайте клиент OpenAI. Если задана переменная `OPENAI_BASE_URL` (для LM Studio/Ollama), используйте её.
2.  **Memory Loop:** Реализуйте цикл:
    *   Считать ввод пользователя.
    *   Добавить сообщение пользователя в историю (`messages`).
    *   Отправить ВСЮ историю в API.
    *   Получить ответ, вывести на экран.
    *   Добавить ответ ассистента в историю.
3.  **System Prompt:** Добавьте в начало истории системное сообщение, которое задает роль: *"Ты опытный Linux администратор. Отвечай кратко и по делу."*

## Запуск с локальной моделью (LM Studio)
1.  Запустите LM Studio -> Start Server (Port 1234).
2.  В терминале:
```bash
export OPENAI_BASE_URL="http://localhost:1234/v1"
export OPENAI_API_KEY="lm-studio"
go run main.go
```
