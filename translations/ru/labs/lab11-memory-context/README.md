# Lab 11: Memory и Context Management

## Цель
Научиться реализовывать системы памяти: долговременное хранилище, извлечение фактов и слои контекста.

## Theory

### Системы памяти

Агентам нужна память для:
- Запоминания прошлых разговоров
- Хранения важных фактов
- Извлечения релевантной информации
- Эффективного управления контекстом

### Типы памяти

**Рабочая память (Кратковременная):**
- Недавние ходы разговора
- Контекст текущей задачи
- Ограничена контекстным окном

**Долговременная память:**
- Важные факты, извлеченные из разговоров
- Предпочтения пользователя
- Прошлые решения и результаты

### Слои контекста

Эффективное управление контекстом использует слои:
- **Слой рабочей памяти** — недавние ходы (последние 5-10 сообщений)
- **Слой саммари** — сжатая история (сжатые старые сообщения)
- **Слой фактов** — извлеченные важные факты

### Извлечение фактов

Не вся информация одинаково важна:
- Имя пользователя, предпочтения → важно (хранить)
- Временный статус → менее важно (можно забыть)
- Принятые решения → важно (хранить)

LLM может извлекать факты из разговора:
- "Имя пользователя — Иван" → Факт
- "Сервер работает" → Временный статус (не факт)

### Саммаризация

Когда контекст переполняется, сжимайте старые сообщения:
- Сохраняйте важную информацию
- Уменьшайте количество токенов
- Поддерживайте непрерывность контекста

См. подробнее:
- [Глава 12: Системы Памяти Агента](../../book/12-agent-memory/README.md)
- [Глава 13: Context Engineering](../../book/13-context-engineering/README.md)

## Задание

В `main.go` реализуйте систему памяти с управлением контекстом.

### Часть 1: Хранилище памяти

Реализуйте интерфейс `Memory`:
- `Store(key string, value any, importance int) error` — сохранить факт с приоритетом
- `Retrieve(query string, limit int) ([]MemoryItem, error)` — найти факты
- `Forget(key string) error` — удалить факт

**Формат хранения:**
- Используйте файловое хранилище (JSON)
- Или in-memory map (для тестирования)

### Часть 2: Извлечение фактов

Реализуйте функцию `extractFacts(conversation string) ([]Fact, error)`:
- Используйте LLM для извлечения важных фактов из разговора
- Оцените факты по важности
- Храните факты отдельно от истории разговора

**Пример:**
```
Разговор: "Привет, меня зовут Иван. Я работаю в TechCorp. Мы используем Docker."
Извлеченные факты:
  - Имя пользователя: Иван
  - Компания пользователя: TechCorp
  - Технологический стек: Docker
```

### Часть 3: Слои контекста

Реализуйте `LayeredContext`:
- **Рабочая память** — недавние ходы (последние 5-10 сообщений)
- **Слой саммари** — сжатая история (сжатые старые сообщения)
- **Слой фактов** — извлеченные факты (извлеченные по релевантности)

**Сборка контекста:**
```
Финальный контекст = System Prompt + Слой фактов + Слой саммари + Рабочая память
```

### Часть 4: Саммаризация

Реализуйте функцию `summarizeConversation(messages []openai.ChatCompletionMessage) (string, error)`:
- Используйте LLM для создания саммари
- Сохраните ключевые факты (имя пользователя, решения, важные события)
- Уменьшите количество токенов (2000 токенов → 200 токенов)

**Пример промпта для саммари:**
```
Создай саммари этого разговора, сохранив только:
1. Важные принятые решения
2. Ключевые обнаруженные факты (имя пользователя, предпочтения)
3. Текущее состояние задачи
Разговор: [сообщения]
```

## Важно

- Извлекайте факты только когда важно (не из каждого сообщения)
- Саммаризируйте, когда контекст превышает 80% лимита
- Всегда сохраняйте System Prompt
- Извлекайте релевантные факты на основе текущего запроса

## Критерии сдачи

✅ **Сдано:**
- Хранилище памяти реализовано
- Извлечение фактов работает
- Слои контекста реализованы
- Саммаризация уменьшает токены
- Агент помнит важные факты
- Факты извлекаются по релевантности

❌ **Не сдано:**
- Нет сохранения памяти
- Факты не извлекаются
- Контекст не слоистый
- Саммаризация теряет важную информацию
- Факты не извлекаются по релевантности

---

**Следующий шаг:** После завершения Lab 11 переходите к [Lab 12: Tool Server Protocol](../lab12-tool-server/README.md).
